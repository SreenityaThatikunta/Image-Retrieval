{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnTrqAMGE90C"
      },
      "source": [
        "#**CNN+ LDA+ KMEANS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQHdtqm_FItG",
        "outputId": "207743e1-43b9-49e8-ed46-f43874ff59af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train cnn Shape: (50000, 2048), Test cnn Shape: (10000, 2048)\n",
            "Train Accuracy: 90.99%\n",
            "Test Accuracy: 89.02%\n",
            "Classification Report (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91      1000\n",
            "           1       0.96      0.92      0.94      1000\n",
            "           2       0.92      0.82      0.87      1000\n",
            "           3       0.70      0.89      0.78      1000\n",
            "           4       0.83      0.90      0.86      1000\n",
            "           5       0.92      0.78      0.85      1000\n",
            "           6       0.92      0.90      0.91      1000\n",
            "           7       0.95      0.87      0.91      1000\n",
            "           8       0.95      0.95      0.95      1000\n",
            "           9       0.94      0.93      0.93      1000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.90      0.89      0.89     10000\n",
            "weighted avg       0.90      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "x_train_cnn = np.load('/content/drive/MyDrive/features_prml/cnn_train.npy')\n",
        "x_test_cnn = np.load('/content/drive/MyDrive/features_prml/cnn_test.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/features_prml/y_train.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/features_prml/y_test.npy')\n",
        "\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()\n",
        "\n",
        "print(f\"Train cnn Shape: {x_train_cnn.shape}, Test cnn Shape: {x_test_cnn.shape}\")\n",
        "\n",
        "\n",
        "                                                                                # Perform LDA for Dimensionality Reduction\n",
        "lda = LDA(n_components=9) # n_components = classes - 1\n",
        "x_train_lda = lda.fit_transform(x_train_cnn, y_train)\n",
        "x_test_lda = lda.transform(x_test_cnn)\n",
        "\n",
        "\n",
        "kmeans_cnn_lda = KMeans(n_clusters=10, random_state=42, n_init=50)              # Apply K-Means Clustering with 10 Clusters\n",
        "kmeans_cnn_lda.fit(x_train_lda)\n",
        "y_train_pred = kmeans_cnn_lda.predict(x_train_lda)\n",
        "y_test_pred = kmeans_cnn_lda.predict(x_test_lda)\n",
        "\n",
        "\n",
        "def map_labels(y_true, y_pred):                                                 # Map cluster labels to actual labels using majority voting\n",
        "    mapping = {}\n",
        "    for i in range(10):\n",
        "        cluster_indices = np.where(y_pred == i)[0]\n",
        "        true_labels = y_true[cluster_indices]\n",
        "        if len(true_labels) > 0:\n",
        "            mapping[i] = np.bincount(true_labels).argmax()\n",
        "    return np.array([mapping[label] for label in y_pred])\n",
        "\n",
        "y_train_pred_mapped = map_labels(y_train, y_train_pred)\n",
        "y_test_pred_mapped = map_labels(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred_mapped)                   # Calculate Accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred_mapped)\n",
        "\n",
        "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(\"Classification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred_mapped))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/prml/checkpoints\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "checkpoint = {\n",
        "    \"kmeans_model\": kmeans_cnn_lda,\n",
        "    \"lda_model\": lda,\n",
        "    \"x_train_lda\": x_train_lda,\n",
        "    \"y_train_pred\": y_train_pred,  # for finding cluster members\n",
        "    \"x_train_images\": x_train_images,  # shape: (50000, 32, 32, 3)\n",
        "    \"train_accuracy\": train_accuracy,\n",
        "    \"test_accuracy\": test_accuracy\n",
        "}\n",
        "\n",
        "with open(os.path.join(save_dir, \"cnn_kmeans_lda_checkpoint.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(checkpoint, f)\n",
        "\n",
        "print(\"Checkpoint saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0es0LIYxvZy8",
        "outputId": "26f424e9-7651-4bd9-f267-0e93cb0115a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iy_qAnd5QnD",
        "outputId": "e721638f-0898-4367-d4eb-e838cb3c595c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load CIFAR-10 training images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "# Convert images to numpy array\n",
        "x_train_images = np.stack([np.transpose(img.numpy(), (1, 2, 0)) * 255 for img, _ in trainset]).astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "-Qvtb1_65WF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/prml/checkpoints\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "checkpoint = {\n",
        "    \"kmeans_model\": kmeans_cnn_lda,\n",
        "    \"lda_model\": lda,\n",
        "    \"x_train_lda\": x_train_lda,\n",
        "    \"y_train_pred\": y_train_pred,  # for finding cluster members\n",
        "    \"x_train_images\": x_train_images,  # shape: (50000, 32, 32, 3)\n",
        "    \"train_accuracy\": train_accuracy,\n",
        "    \"test_accuracy\": test_accuracy\n",
        "}\n",
        "\n",
        "with open(os.path.join(save_dir, \"cnn_kmeans_lda_checkpoint.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(checkpoint, f)\n",
        "\n",
        "print(\"Checkpoint saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTQRiRTr95kU",
        "outputId": "07c2d68c-83fb-4282-8e00-0acca7b1c981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved successfully.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}